"""
é˜¿é‡Œå·´å·´æ•°æ®é›†lossä¸åŠ¨é—®é¢˜çš„å®Œæ•´è§£å†³æ–¹æ¡ˆ
å±•ç¤ºä¿®å¤åŽçš„è®­ç»ƒè¿‡ç¨‹
"""

import torch
import torch.optim as optim
import numpy as np
import matplotlib.pyplot as plt
from fixed_alibaba_dataloader import FixedAlibabaDataset, create_larger_sample_data
from lightgcn_model import LightGCN, BPRLoss
import time
from tqdm import tqdm

class ImprovedLightGCNTrainer:
    """æ”¹è¿›çš„LightGCNè®­ç»ƒå™¨ï¼Œè§£å†³lossä¸åŠ¨é—®é¢˜"""
    
    def __init__(self, model, dataset, learning_rate=0.001, weight_decay=1e-5, 
                 batch_size=1024, device='cpu'):
        self.model = model.to(device)
        self.dataset = dataset
        self.device = device
        self.batch_size = batch_size
        
        # ä½¿ç”¨æ›´å°çš„æƒé‡è¡°å‡
        self.optimizer = optim.Adam(
            self.model.parameters(), 
            lr=learning_rate, 
            weight_decay=weight_decay
        )
        
        # ä½¿ç”¨æ›´å°çš„æ­£åˆ™åŒ–ç³»æ•°
        self.criterion = BPRLoss(lambda_reg=weight_decay)
        
        # è®­ç»ƒåŽ†å²
        self.train_losses = []
        self.bpr_losses = []
        self.reg_losses = []
        
        # èŽ·å–å›¾æ•°æ®
        self.edge_index = dataset.get_edge_index().to(device)
        self.train_data = dataset.get_train_data()
        self.test_data = dataset.get_test_data()
        self.user_item_dict = dataset.get_user_item_interactions()
        
        print(f"âœ… è®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ:")
        print(f"- è®¾å¤‡: {device}")
        print(f"- æ‰¹æ¬¡å¤§å°: {batch_size}")
        print(f"- å­¦ä¹ çŽ‡: {learning_rate}")
        print(f"- æƒé‡è¡°å‡: {weight_decay}")
        print(f"- è®­ç»ƒæ ·æœ¬æ•°: {len(self.train_data)}")
    
    def train_epoch(self):
        """è®­ç»ƒä¸€ä¸ªepoch"""
        self.model.train()
        total_loss = 0
        total_bpr_loss = 0
        total_reg_loss = 0
        num_batches = 0
        
        # éšæœºæ‰“ä¹±è®­ç»ƒæ•°æ®
        indices = np.random.permutation(len(self.train_data))
        
        # åˆ†æ‰¹è®­ç»ƒ
        pbar = tqdm(range(0, len(indices), self.batch_size), desc="Training")
        
        for start_idx in pbar:
            end_idx = min(start_idx + self.batch_size, len(indices))
            batch_indices = indices[start_idx:end_idx]
            
            # èŽ·å–æ‰¹æ¬¡æ•°æ®
            batch_users = []
            batch_pos_items = []
            batch_neg_items = []
            
            for idx in batch_indices:
                user_id, pos_item_id = self.train_data[idx]
                neg_item_id = self.dataset.negative_sampling(user_id, 1)[0]
                
                batch_users.append(user_id)
                batch_pos_items.append(pos_item_id)
                batch_neg_items.append(neg_item_id)
            
            # è½¬æ¢ä¸ºå¼ é‡
            user_ids = torch.LongTensor(batch_users).to(self.device)
            pos_item_ids = torch.LongTensor(batch_pos_items).to(self.device)
            neg_item_ids = torch.LongTensor(batch_neg_items).to(self.device)
            
            # è®¡ç®—é¢„æµ‹å¾—åˆ†
            pos_scores = self.model.predict(user_ids, pos_item_ids, self.edge_index)
            neg_scores = self.model.predict(user_ids, neg_item_ids, self.edge_index)
            
            # è®¡ç®—æŸå¤±
            loss = self.criterion(pos_scores, neg_scores, self.model)
            
            # å•ç‹¬è®¡ç®—BPRæŸå¤±å’Œæ­£åˆ™åŒ–æŸå¤±ç”¨äºŽç›‘æŽ§
            bpr_loss = -torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-8).mean()
            reg_loss = sum(torch.norm(param, p=2) ** 2 for param in self.model.parameters())
            reg_loss = self.criterion.lambda_reg * reg_loss
            
            # åå‘ä¼ æ’­
            self.optimizer.zero_grad()
            loss.backward()
            
            # æ¢¯åº¦è£å‰ªï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
            
            self.optimizer.step()
            
            total_loss += loss.item()
            total_bpr_loss += bpr_loss.item()
            total_reg_loss += reg_loss.item()
            num_batches += 1
            
            # æ›´æ–°è¿›åº¦æ¡
            pbar.set_postfix({
                'Loss': f'{loss.item():.4f}',
                'BPR': f'{bpr_loss.item():.4f}',
                'Reg': f'{reg_loss.item():.4f}'
            })
        
        avg_loss = total_loss / num_batches
        avg_bpr_loss = total_bpr_loss / num_batches
        avg_reg_loss = total_reg_loss / num_batches
        
        return avg_loss, avg_bpr_loss, avg_reg_loss
    
    def train(self, num_epochs=50, print_every=5):
        """è®­ç»ƒæ¨¡åž‹"""
        print(f"\nðŸš€ å¼€å§‹è®­ç»ƒï¼Œå…±{num_epochs}è½®...")
        
        for epoch in range(num_epochs):
            start_time = time.time()
            
            # è®­ç»ƒä¸€ä¸ªepoch
            train_loss, bpr_loss, reg_loss = self.train_epoch()
            
            # è®°å½•åŽ†å²
            self.train_losses.append(train_loss)
            self.bpr_losses.append(bpr_loss)
            self.reg_losses.append(reg_loss)
            
            epoch_time = time.time() - start_time
            
            # å®šæœŸæ‰“å°è¿›åº¦
            if (epoch + 1) % print_every == 0:
                print(f"\nEpoch {epoch+1}/{num_epochs}")
                print(f"æ€»æŸå¤±: {train_loss:.6f}")
                print(f"BPRæŸå¤±: {bpr_loss:.6f}")
                print(f"æ­£åˆ™åŒ–æŸå¤±: {reg_loss:.6f}")
                print(f"è®­ç»ƒæ—¶é—´: {epoch_time:.2f}ç§’")
                
                # æ£€æŸ¥æŸå¤±å˜åŒ–
                if epoch >= 10:
                    recent_losses = self.train_losses[-10:]
                    loss_change = abs(recent_losses[-1] - recent_losses[0])
                    if loss_change < 1e-6:
                        print("âš ï¸  æŸå¤±å˜åŒ–å¾ˆå°ï¼Œå¯èƒ½éœ€è¦è°ƒæ•´å­¦ä¹ çŽ‡")
                    else:
                        print(f"âœ… æŸå¤±å˜åŒ–: {loss_change:.6f}")
        
        print("\nðŸŽ‰ è®­ç»ƒå®Œæˆ!")
        return {
            'train_losses': self.train_losses,
            'bpr_losses': self.bpr_losses,
            'reg_losses': self.reg_losses
        }
    
    def plot_training_curves(self, save_path=None):
        """ç»˜åˆ¶è®­ç»ƒæ›²çº¿"""
        fig, axes = plt.subplots(1, 3, figsize=(15, 4))
        
        epochs = range(1, len(self.train_losses) + 1)
        
        # æ€»æŸå¤±
        axes[0].plot(epochs, self.train_losses, 'b-', linewidth=2)
        axes[0].set_title('æ€»æŸå¤± (Total Loss)')
        axes[0].set_xlabel('Epoch')
        axes[0].set_ylabel('Loss')
        axes[0].grid(True, alpha=0.3)
        
        # BPRæŸå¤±
        axes[1].plot(epochs, self.bpr_losses, 'r-', linewidth=2)
        axes[1].set_title('BPRæŸå¤±')
        axes[1].set_xlabel('Epoch')
        axes[1].set_ylabel('BPR Loss')
        axes[1].grid(True, alpha=0.3)
        
        # æ­£åˆ™åŒ–æŸå¤±
        axes[2].plot(epochs, self.reg_losses, 'g-', linewidth=2)
        axes[2].set_title('æ­£åˆ™åŒ–æŸå¤±')
        axes[2].set_xlabel('Epoch')
        axes[2].set_ylabel('Regularization Loss')
        axes[2].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"è®­ç»ƒæ›²çº¿å·²ä¿å­˜åˆ°: {save_path}")
        
        plt.show()


def test_different_configurations():
    """æµ‹è¯•ä¸åŒçš„é…ç½®ä»¥æ‰¾åˆ°æœ€ä½³è®¾ç½®"""
    print("ðŸ§ª æµ‹è¯•ä¸åŒçš„é…ç½®ä»¥è§£å†³lossä¸åŠ¨é—®é¢˜...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    data_path = "./solution_test_data"
    create_larger_sample_data(data_path)
    
    # é…ç½®ç»„åˆ
    configs = [
        {"name": "é…ç½®1: åŽŸå§‹è®¾ç½®", "lr": 0.001, "wd": 1e-4, "min_inter": 5},
        {"name": "é…ç½®2: é™ä½Žæ­£åˆ™åŒ–", "lr": 0.001, "wd": 1e-5, "min_inter": 5},
        {"name": "é…ç½®3: æé«˜å­¦ä¹ çŽ‡", "lr": 0.01, "wd": 1e-5, "min_inter": 5},
        {"name": "é…ç½®4: é™ä½Žè¿‡æ»¤æ¡ä»¶", "lr": 0.001, "wd": 1e-5, "min_inter": 2},
    ]
    
    results = {}
    
    for config in configs:
        print(f"\n{'='*60}")
        print(f"ðŸ”§ æµ‹è¯• {config['name']}")
        print(f"{'='*60}")
        
        try:
            # åŠ è½½æ•°æ®é›†
            dataset = FixedAlibabaDataset(
                data_path=data_path,
                behavior_types=[4],
                min_user_interactions=config['min_inter'],
                min_item_interactions=config['min_inter'],
                test_size=0.2
            )
            
            # åˆ›å»ºæ¨¡åž‹
            model = LightGCN(
                num_users=dataset.num_users,
                num_items=dataset.num_items,
                embedding_dim=64,
                num_layers=3,
                dropout=0.1
            )
            
            # åˆ›å»ºè®­ç»ƒå™¨
            trainer = ImprovedLightGCNTrainer(
                model=model,
                dataset=dataset,
                learning_rate=config['lr'],
                weight_decay=config['wd'],
                batch_size=512,
                device='cpu'
            )
            
            # è®­ç»ƒæ¨¡åž‹
            history = trainer.train(num_epochs=20, print_every=5)
            
            # åˆ†æžç»“æžœ
            final_loss = history['train_losses'][-1]
            loss_reduction = history['train_losses'][0] - final_loss
            loss_stable = abs(history['train_losses'][-1] - history['train_losses'][-5]) < 1e-6
            
            results[config['name']] = {
                'final_loss': final_loss,
                'loss_reduction': loss_reduction,
                'loss_stable': loss_stable,
                'data_stats': dataset.get_data_statistics()
            }
            
            print(f"âœ… {config['name']} å®Œæˆ")
            print(f"   æœ€ç»ˆæŸå¤±: {final_loss:.6f}")
            print(f"   æŸå¤±ä¸‹é™: {loss_reduction:.6f}")
            print(f"   æ˜¯å¦ç¨³å®š: {'æ˜¯' if not loss_stable else 'å¦'}")
            
        except Exception as e:
            print(f"âŒ {config['name']} å¤±è´¥: {e}")
            results[config['name']] = {'error': str(e)}
    
    # æ€»ç»“ç»“æžœ
    print(f"\n{'='*60}")
    print("ðŸ“Š é…ç½®æµ‹è¯•ç»“æžœæ€»ç»“")
    print(f"{'='*60}")
    
    for name, result in results.items():
        print(f"\n{name}:")
        if 'error' in result:
            print(f"  âŒ é”™è¯¯: {result['error']}")
        else:
            print(f"  æœ€ç»ˆæŸå¤±: {result['final_loss']:.6f}")
            print(f"  æŸå¤±ä¸‹é™: {result['loss_reduction']:.6f}")
            print(f"  æ•°æ®ç»Ÿè®¡: ç”¨æˆ·{result['data_stats']['num_users']}, å•†å“{result['data_stats']['num_items']}, äº¤äº’{result['data_stats']['num_interactions']}")
    
    return results


def main():
    """ä¸»å‡½æ•°ï¼šå±•ç¤ºå®Œæ•´çš„è§£å†³æ–¹æ¡ˆ"""
    print("ðŸŽ¯ é˜¿é‡Œå·´å·´æ•°æ®é›†Lossä¸åŠ¨é—®é¢˜çš„å®Œæ•´è§£å†³æ–¹æ¡ˆ")
    print("="*60)
    
    # 1. é—®é¢˜è¯Šæ–­æ€»ç»“
    print("\nðŸ“‹ é—®é¢˜è¯Šæ–­æ€»ç»“:")
    print("ä¸»è¦é—®é¢˜: æ•°æ®é¢„å¤„ç†è¿‡äºŽä¸¥æ ¼ï¼Œå¯¼è‡´è®­ç»ƒæ•°æ®ä¸è¶³")
    print("å…·ä½“åŽŸå› :")
    print("1. æœ€å°äº¤äº’æ¬¡æ•°è®¾ç½®ä¸º5ï¼Œè¿‡æ»¤æŽ‰äº†å¤§é‡æ•°æ®")
    print("2. åªä¿ç•™è´­ä¹°è¡Œä¸º(ç±»åž‹4)ï¼Œæ•°æ®é‡è¿›ä¸€æ­¥å‡å°‘")
    print("3. å•†å“å­é›†è¿‡æ»¤åˆå‡å°‘äº†æ•°æ®")
    print("4. æœ€ç»ˆå¯¼è‡´è®­ç»ƒæ•°æ®ä¸ºç©ºæˆ–æžå°‘")
    
    # 2. è§£å†³æ–¹æ¡ˆ
    print("\nðŸ”§ è§£å†³æ–¹æ¡ˆ:")
    print("1. é™ä½Žæœ€å°äº¤äº’æ¬¡æ•°è¦æ±‚ (5 â†’ 2)")
    print("2. å‡å°‘æ­£åˆ™åŒ–å¼ºåº¦ (1e-4 â†’ 1e-5)")
    print("3. è°ƒæ•´å­¦ä¹ çŽ‡å’Œä¼˜åŒ–å™¨è®¾ç½®")
    print("4. å¢žåŠ æ¢¯åº¦è£å‰ªé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸")
    print("5. æ”¹è¿›è´Ÿé‡‡æ ·æ–¹æ³•")
    
    # 3. è¿è¡Œæµ‹è¯•
    results = test_different_configurations()
    
    # 4. æœ€ä½³å®žè·µå»ºè®®
    print(f"\nðŸ’¡ æœ€ä½³å®žè·µå»ºè®®:")
    print("1. æ•°æ®é¢„å¤„ç†:")
    print("   - ç”¨æˆ·æœ€å°äº¤äº’æ¬¡æ•°: 2-3")
    print("   - å•†å“æœ€å°äº¤äº’æ¬¡æ•°: 2-3")
    print("   - ä¿ç•™æ›´å¤šè¡Œä¸ºç±»åž‹ [3,4] è€Œä¸æ˜¯åªæœ‰ [4]")
    print()
    print("2. æ¨¡åž‹å‚æ•°:")
    print("   - å­¦ä¹ çŽ‡: 0.001-0.01")
    print("   - æƒé‡è¡°å‡: 1e-5 åˆ° 1e-6")
    print("   - æ‰¹æ¬¡å¤§å°: 512-2048")
    print("   - åµŒå…¥ç»´åº¦: 64-128")
    print()
    print("3. è®­ç»ƒç­–ç•¥:")
    print("   - ä½¿ç”¨æ¢¯åº¦è£å‰ª")
    print("   - ç›‘æŽ§BPRæŸå¤±å’Œæ­£åˆ™åŒ–æŸå¤±")
    print("   - å®šæœŸæ£€æŸ¥æŸå¤±å˜åŒ–")
    print("   - ä½¿ç”¨å­¦ä¹ çŽ‡è°ƒåº¦å™¨")
    
    print(f"\nâœ… è§£å†³æ–¹æ¡ˆæ¼”ç¤ºå®Œæˆï¼")


if __name__ == "__main__":
    main()